obstacle world 및 kobuki 생성 (environment = v1)
 $ roslaunch IRL_learning_ros training.launch
DQN node 실행
 $ roslaunch IRL_learning_ros deepQlearning.launch

DQN node 실행( ex) model data's episode = 660, environment = v1)
	v0 : input = 9
	v1 : input = 11
	v2 : input = 11+5(action_buffer)

roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v1'

=========================================================================================================

컨퍼런스용
action_buffer를 사용하였을 때와 하지 않았을 때의 스코어 달성 차이 비교

사용하지 않았을 때
$ roslaunch IRL_learning_ros traning.launch

$ roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v2'-->(train2015.py로 변경)
	 --> train : 2015
	     state_publisher : v1
	     effort_publisher : v2

<<<<<<< HEAD
사용했을 때
$ roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v2' 
=======
$ roslaunch IRL_learning_ros deepQlearning.launch env:=v2 -->(train2017.py로 변경)
>>>>>>> master
	 --> train : 2017
	     state_publisher : v1
	     effort_publisher : v2

========================================================================================================= 
DR SLAM
(Using OpenCV)

$ roslaunch IRL_learning_ros traning.launch

$ rosrun IRL_learning_ros mapper.py

$ rosrun rosrun kobuki_tf kobuki_tf 

$ rosrun rviz rviz


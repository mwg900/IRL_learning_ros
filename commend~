obstacle world 및 kobuki 생성 (environment = v1)
 $ roslaunch IRL_learning_ros training.launch
DQN node 실행
 $ roslaunch IRL_learning_ros deepQlearning.launch

DQN node 실행( ex) model data's episode = 660, environment = v1)
	v0 : input = 9
	v1 : input = 11
	v2 : input = 11+5(action_buffer)

roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v1'



컨퍼런스용
action_buffer를 사용하였을 때와 하지 않았을 때의 스코어 달성 차이 비교

사용하지 않았을 때
$ roslaunch IRL_learning_ros traning.launch

$ roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v2'
	 --> train : 2015
	     state_publisher : v1
	     effort_publisher : v2

$ roslaunch IRL_learning_ros deepQlearning.launch data:=660 env:='v2' -->(train2015.py로 변경)
	 --> train : 2017
	     state_publisher : v1
	     effort_publisher : v2
